{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPE7ZbjlVO7yo9tuzdd99nE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/MasterAI/blob/master/DLMindMap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CT5145 Deep Learning Exam - Full Answer Key & Explanation\n",
        "\n",
        "#2023_2024_CT5145_1_2_3\n",
        "---\n",
        "\n",
        "#### Question 1: Multiple Choice (25 marks)\n",
        "Each correct answer gives 1 mark. Some questions have multiple correct answers. No negative marking.\n",
        "\n",
        "1. **Which one of the following is a hypothesis language?**  \n",
        "✅ Logistic regression – it defines a set of functions (hypotheses) mapping inputs to outputs.\n",
        "\n",
        "2. **Which of the following ensemble techniques uses subsets of the attributes?**  \n",
        "✅ Random Forests – each tree uses a subset of features.\n",
        "\n",
        "3. **Which one of the following statements about Bagging is true?**  \n",
        "✅ It reduces variance by combining models trained on different samples.\n",
        "\n",
        "4. **Which of these statements about ReLU is TRUE?**  \n",
        "✅ Its output is from 0 to infinity. It's 0 if input is negative, else it's input itself.\n",
        "\n",
        "5. **Derivative of Leaky ReLU?**  \n",
        "✅ f'(z) = 1 if z > 0; ✅ f'(z) = 0.01 if z < 0 – avoids zero gradients.\n",
        "\n",
        "6. **Logistic activation function?**  \n",
        "✅ 1 / (1 + e^-z) – maps input to (0,1).\n",
        "\n",
        "7. **True about batch sizes:**  \n",
        "✅ Full Batch: N = B; ✅ Mini-Batch: B << N\n",
        "\n",
        "8. **Structured data in medical context:**  \n",
        "✅ Age, weight, height; ✅ blood pressure daily – these are tabular, numerical formats.\n",
        "\n",
        "9. **Break symmetry in neural nets:**  \n",
        "✅ Randomly initialize weights – ensures neurons learn different things.\n",
        "\n",
        "10. **Early stopping statements:**  \n",
        "✅ Prevents overfitting; ✅ saves best model; ✅ uses validation set\n",
        "\n",
        "11. **Saddle point characteristics:**  \n",
        "✅ Max in some, min in others; ✅ gradient = 0 – not strictly min or max.\n",
        "\n",
        "12. **False statement about L2 regularization:**  \n",
        "❌ It drops nodes – that’s dropout, not L2.\n",
        "\n",
        "13. **U-Net output:**  \n",
        "✅ Image with one channel per class – segmentation masks.\n",
        "\n",
        "14. **YOLO application:**  \n",
        "✅ Detecting objects (e.g., traffic lights) – real-time object detection.\n",
        "\n",
        "15. **Benefit of residual connections:**  \n",
        "✅ Help gradients flow in deep networks – avoid vanishing gradients.\n",
        "\n",
        "16. **Why Batch Norm is used:**  \n",
        "✅ Normalize layer inputs to stabilize training and speed convergence.\n",
        "\n",
        "17. **Orthogonality thesis:**  \n",
        "✅ Intelligence is separate from goals – smart doesn’t mean good.\n",
        "\n",
        "18. **What is a pretext task?**  \n",
        "✅ Auxiliary task for self-supervised learning (e.g., predicting rotation).\n",
        "\n",
        "19. **Effect of 1x1 conv:**  \n",
        "✅ Reduces input depth (channels), allows mixing info across channels.\n",
        "\n",
        "20. **Parameters in conv layer:**  \n",
        "Input: 100x100x3, filter: 3x3x3, 10 filters → 3x3x3x10 + 10 = ✅ 280 params.\n",
        "\n",
        "21. **Maximally-activating images:**  \n",
        "✅ Reveal what a single neuron responds to most.\n",
        "\n",
        "22. **Main advantage of LSTM:**  \n",
        "✅ Retains useful info longer than vanilla RNN.\n",
        "\n",
        "23. **Dimensionality of cell vs memory state in LSTM:**  \n",
        "✅ Usually the same – defined by model.\n",
        "\n",
        "24. **LSTM candidate updates:**  \n",
        "✅ h = memory state; U = weight matrix\n",
        "\n",
        "25. **Teacher forcing means:**  \n",
        "✅ Using the true label as input at next time step during training\n",
        "\n",
        "---\n",
        "\n",
        "#### Question 2: Logistic Regression & Ensembles\n",
        "(a) **Logistic Regression Algorithm**\n",
        "1. **Initialize** weights W and bias b to small random numbers\n",
        "2. **Forward Propagation**:\n",
        "   z = XW + b  \n",
        "   a = sigmoid(z)\n",
        "3. **Cost Function**: Binary cross-entropy\n",
        "   L = -1/m * sum(y*log(a) + (1-y)*log(1-a))\n",
        "4. **Backward Propagation**: compute gradients dW, db\n",
        "5. **Gradient Descent**: update weights and bias\n",
        "6. **Repeat until convergence**\n",
        "\n",
        "(b) **Relation to Neural Networks**\n",
        "- Logistic regression = 1-layer neural net with sigmoid\n",
        "- NN = deeper networks, more layers, nonlinear features\n",
        "- **Decision boundary**: surface separating classes (linear for LR, nonlinear for NNs)\n",
        "\n",
        "(c) **Ensemble Techniques**\n",
        "- Combine multiple models to reduce overfitting and variance\n",
        "- E.g., voting on predictions\n",
        "\n",
        "(d) **Bagging**\n",
        "- Generate multiple classifiers on bootstrapped subsets\n",
        "- Combine via majority vote or averaging\n",
        "\n",
        "---\n",
        "\n",
        "#### Question 3: CNNs and Convolutions\n",
        "(a) **Convolution Calculation** (stride=2, no padding):\n",
        "- Perform elementwise multiply and sum over 3x3 sections, stepping by 2\n",
        "- Result: 2x2 matrix: [11, 15; 13, 11]\n",
        "\n",
        "(b) **Output Size Formula**:\n",
        "\\[ \\text{Output size} = \\left\\lfloor \\frac{N - F}{S} + 1 \\right\\rfloor \\]\n",
        "- (a) -> (5 - 3)/2 + 1 = 2\n",
        "- (b) with stride 1 -> (5 - 3)/1 + 1 = 3\n",
        "\n",
        "(c) **Pooling**:\n",
        "- Reduces spatial size\n",
        "- Types: max pooling, average pooling\n",
        "- Example: 2x2 max pool (stride=2): [4, 5; 5, 2]\n",
        "\n",
        "(d) **3D Convolution**:\n",
        "- Needed for multi-channel input or video\n",
        "- Third dimension = number of input channels (determined by data)\n",
        "- Output has one value per filter per spatial location\n",
        "\n",
        "---\n",
        "\n",
        "#### Question 4: Embeddings\n",
        "(a) **Embedding**: Low-dimensional representation of input data\n",
        "\n",
        "(b) **Desirable Properties**:\n",
        "- Similar inputs → similar embeddings\n",
        "- Compact\n",
        "- Discriminative\n",
        "- Stable under noise\n",
        "\n",
        "(c) **VAE Embedding**: Mean and variance vectors in encoder's latent space\n",
        "\n",
        "(d) **GAN Embedding**: False. GANs have implicit latent space input\n",
        "\n",
        "(e) **Applications**: Image search, recommendation systems, language models\n",
        "\n",
        "(f) **CLIP-style Joint Embedding**:\n",
        "- Use image-text pairs\n",
        "- Train image encoder & text encoder jointly\n",
        "- Loss: Contrastive Loss (e.g. InfoNCE)\n",
        "- Data: matched (and unmatched) image-text pairs\n",
        "\n",
        "---\n",
        "\n",
        "#### Question 5: Generative Models\n",
        "(a) **Autoregressive**: Each output depends on previous outputs\n",
        "\n",
        "(b) **Fill-in**: Output = vector/logits; Converted to token by **argmax** or **sampling**\n",
        "\n",
        "(c) **RLHF**:\n",
        "- Human feedback used to fine-tune model\n",
        "- Align output with human preferences\n",
        "\n",
        "(d) **Diffusion Architecture**: U-Net\n",
        "- Task: Denoise the image at each step\n",
        "\n",
        "(e) **Inpainting**: Provide masked input + known pixels; condition diffusion on known\n",
        "\n",
        "(f) **Matching Disadvantages**:\n",
        "- GAN: Mode collapse\n",
        "- VAE: Low-quality samples\n",
        "- Diffusion: Slow generation\n",
        "\n",
        "---\n",
        "\n",
        "✅ All exam questions are now answered with detailed explanations.\n",
        "\n"
      ],
      "metadata": {
        "id": "GvnlARWncBx-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CT5145 Deep Learning Exam - Full Answer Key & Explanation\n",
        "\n",
        "#2023_2024_CT5145_1_1_2\n",
        "---\n",
        "\n",
        "#### Question 1: Multiple Choice (25 marks)\n",
        "Each correct answer gives 1 mark. Some questions have multiple correct answers. No negative marking.\n",
        "\n",
        "**This version of Question 1 is from the Semester 2 paper:**\n",
        "\n",
        "1. **Unsupervised learning task?**  \n",
        "✅ Grouping photos – no labels are used, so it’s clustering.\n",
        "\n",
        "2. **Hypothesis language?**  \n",
        "✅ Logistic regression – defines a mapping from input to output.\n",
        "\n",
        "3. **Binary classification in NN:**  \n",
        "✅ \\( \\hat{y} \\) approximates \\( y \\); ✅ \\( \\hat{y} \\) is output of final neuron; ✅ \\( \\hat{y} = \\sigma(w \\cdot x + b) \\)\n",
        "\n",
        "4. **Classification but not regression?**  \n",
        "✅ Logistic Regression – outputs probabilities, suited for classification.\n",
        "\n",
        "5. **FALSE about Leaky ReLU?**  \n",
        "✅ It is a linear function ❌ – it’s piecewise linear, but not fully linear.\n",
        "\n",
        "6. **Logistic activation function:**  \n",
        "✅ 1 / (1 + e^-z) – sigmoid function.\n",
        "\n",
        "7. **ReLU derivative:**  \n",
        "✅ f'(z) = 1 if z > 0; ✅ f'(z) = 0 if z < 0\n",
        "\n",
        "8. **Mini-batch gradient descent:**  \n",
        "✅ One epoch = N / B iterations\n",
        "\n",
        "9. **Early stopping:**  \n",
        "✅ Prevents overfitting; ✅ Saves best model; ✅ Uses validation set\n",
        "\n",
        "10. **NOT adversarial attack:**  \n",
        "✅ Misclassifying a horse as a donkey isn’t adversarial unless crafted – others are intentional misleadings.\n",
        "\n",
        "11. **Saddle point:**  \n",
        "✅ Max in some dimensions, min in others.\n",
        "\n",
        "12. **Trainable parameters in CNN:**  \n",
        "✅ Filter values – learned by backprop.\n",
        "\n",
        "13. **U-net output:**  \n",
        "✅ Image-shaped output, one channel per class.\n",
        "\n",
        "14. **YOLO application:**  \n",
        "✅ Detecting traffic lights – object detection.\n",
        "\n",
        "15. **Autoencoder vs GAN components:**  \n",
        "✅ AE decoder = GAN generator – both generate outputs from internal representation.\n",
        "\n",
        "16. **Residual connections:**  \n",
        "✅ Allow gradient propagation – skip connections help deeper models train.\n",
        "\n",
        "17. **Batch Normalisation:**  \n",
        "✅ Stabilises input distribution to layers.\n",
        "\n",
        "18. **Instrumental convergence:**  \n",
        "✅ AI may seek resources/power regardless of goal – a safety concern.\n",
        "\n",
        "19. **Pretext task:**  \n",
        "✅ Artificial but useful task to learn representations.\n",
        "\n",
        "20. **1x1 conv effect:**  \n",
        "✅ Reduces depth – mixes info across channels.\n",
        "\n",
        "21. **VAE vs AE:**  \n",
        "✅ VAE includes sampling step.\n",
        "\n",
        "22. **VAE training objective:**  \n",
        "✅ Minimise reconstruction loss + KL divergence (not explicitly listed, but best fit = minimize input-output difference).\n",
        "\n",
        "23. **Conv layer params example:**  \n",
        "3x3 kernel × 3 channels × 10 filters + 10 biases = 280 ✅\n",
        "\n",
        "24. **Maximally-activating images:**  \n",
        "✅ Show what neuron is most sensitive to.\n",
        "\n",
        "25. **LSTM vs RNN:**  \n",
        "✅ LSTM retains information longer – via gating mechanisms.\n",
        "\n",
        "---\n",
        "\n",
        "#### Question 2: Neural Network Training Steps\n",
        "(a) **Forward Propagation:**  \n",
        "Given inputs \\( x \\), weights \\( W \\), bias \\( b \\):\n",
        "\n",
        "- \\( z = W \\cdot x + b \\)\n",
        "- \\( a = \\text{activation}(z) \\), e.g., ReLU or sigmoid\n",
        "\n",
        "**Python example:**\n",
        "```python\n",
        "z = np.dot(W, x) + b\n",
        "if activation == 'relu':\n",
        "    a = np.maximum(0, z)\n",
        "elif activation == 'sigmoid':\n",
        "    a = 1 / (1 + np.exp(-z))\n",
        "```\n",
        "\n",
        "(b) **Backpropagation + SGD:**\n",
        "- Compute loss (e.g., MSE or cross-entropy)\n",
        "- Compute gradients:\n",
        "  \\( dW = \\frac{\\partial L}{\\partial W} \\), \\( db = \\frac{\\partial L}{\\partial b} \\)\n",
        "- Update parameters:\n",
        "  \\( W = W - \\alpha dW \\), \\( b = b - \\alpha db \\)\n",
        "\n",
        "**Python example:**\n",
        "```python\n",
        "loss = y_hat - y\n",
        "dW = loss * x.T\n",
        "db = loss\n",
        "W -= lr * dW\n",
        "b -= lr * db\n",
        "```\n",
        "\n",
        "(c) **Initialisation & Stopping:**\n",
        "- Initialise \\( W \\sim \\mathcal{N}(0, \\sigma^2) \\), \\( b = 0 \\)\n",
        "- Stop when loss < threshold or max epochs reached\n",
        "\n",
        "(d) **RMSProp:**\n",
        "- Keeps moving average of squared gradients\n",
        "- Update rule:\n",
        "```python\n",
        "E[g^2] = decay * E[g^2] + (1 - decay) * g^2\n",
        "W -= lr / sqrt(E[g^2] + epsilon) * g\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### Question 3: CNN for Recycling Classification\n",
        "(a) **Output layer:**  \n",
        "- 3 nodes for each class\n",
        "- Activation: Softmax\n",
        "- Predict class with highest softmax score\n",
        "\n",
        "(b) **Filters & Feature Maps:**  \n",
        "- A filter (kernel) slides over the image\n",
        "- Performs dot product and generates feature map\n",
        "- Conv layer = multiple filters + activation + optional pooling\n",
        "\n",
        "(c) **Pooling Layer:**  \n",
        "- Reduces size\n",
        "- Max pooling selects max in region\n",
        "- Stride = step size of filter\n",
        "\n",
        "(d) **Data Augmentation:**  \n",
        "- Techniques: rotation, flipping, zooming\n",
        "- Purpose: increase generalisation, reduce overfitting\n",
        "- Apply to bottle/can images to simulate different angles/lighting\n",
        "\n",
        "(e) **Local Minima vs Saddle Points:**  \n",
        "- Saddle: min in one direction, max in another\n",
        "- DL tends to get stuck in saddle points more due to high dimensionality\n",
        "\n",
        "---\n",
        "\n",
        "#### Question 4: CLIP Model\n",
        "(a) **Required data:**  \n",
        "- Pairs of image and matching text\n",
        "- Sources: image captions, alt text (e.g., LAION-5B, OpenImages)\n",
        "\n",
        "(b) **Frozen Pre-trained Models:**  \n",
        "- Yes, can use frozen encoders and only train projection layers\n",
        "- Saves compute, preserves pre-trained features\n",
        "\n",
        "(c) **Objective:**  \n",
        "- Maximize similarity for matching pairs, minimize for others\n",
        "- Use contrastive loss:\n",
        "\\[ L = -\\log \\frac{e^{\\text{sim}(I, T)/\\tau}}{\\sum_j e^{\\text{sim}(I, T_j)/\\tau}} \\]\n",
        "\n",
        "(d) **Applications:**  \n",
        "- Zero-shot image classification\n",
        "- Text-based image retrieval\n",
        "- Prompt-based image search (\"Show me a photo of a golden retriever\")\n",
        "\n",
        "(e) **Other Modalities:**  \n",
        "- Yes, e.g., Audio-Text (CLAP), Video-Text, Sensor-Text\n",
        "\n",
        "(f) **Ethical Issues:**  \n",
        "- Bia"
      ],
      "metadata": {
        "id": "LTxcr5uCeDIx"
      }
    }
  ]
}